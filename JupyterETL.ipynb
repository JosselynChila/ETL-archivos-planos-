{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob \nimport pandas as pd \nimport xml.etree.ElementTree as ET \nfrom datetime import datetime\nimport requests\nfrom zipfile import ZipFile\n\ndef get_data():\n    print('Iniciar descarga de archivos')\n    remote_url = 'http://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip'\n    # Defina el nombre del archivo local para guardar datos\n    local_file = 'datasource.zip'\n    # Realizar una solicitud http para datos de archivos remotos\n    data = requests.get(remote_url)\n    # Guarde los datos del archivo en una copia local\n    with open(local_file, 'wb') as f:\n        f.write(data.content)\n    with ZipFile(local_file, 'r') as zipObj:\n        # Extrae todo el contenido del archivo zip en un directorio diferente\n        zipObj.extractall('dealership_data')\n\ndef extract_from_csv(file_to_process): \n    dataframe = pd.read_csv(file_to_process) \n    return dataframe\n\ndef extract_from_csv(file_to_process): \n    dataframe = pd.read_csv(file_to_process) \n    return dataframe\n\ndef extract_from_json(file_to_process):\n    dataframe = pd.read_json(file_to_process, lines=True)\n    return dataframe\n\ndef extract_from_xml(file_to_process):\n    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n    tree = ET.parse(file_to_process) \n    root = tree.getroot() \n    for person in root: \n        car_model = person.find(\"car_model\").text \n        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n        price = float(person.find(\"price\").text) \n        fuel = person.find(\"fuel\").text \n        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True) \n    return dataframe\n    \ndef extract():\n    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) \n    #for csv files\n    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n    #for json files\n    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n    #for xml files\n    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n    return extracted_data\n   \ndef transform(data):\n    data['price'] = round(data.price, 2)\n    return data\n\ndef load(targetfile, data_to_load):\n    data_to_load.to_csv(targetfile)\n\ndef log(logfile, message):\n    timestamp_format = '%H:%M:%S-%h-%d-%Y'\n    #Hour-Minute-Second-MonthName-Day-Year\n    now = datetime.now() # get current timestamp\n    timestamp = now.strftime(timestamp_format)\n    with open(logfile,\"a\") as f: \n        f.write('[' + timestamp + ']: ' + message + '\\n')\n        print(message)\n\n\nif __name__ == '__main__':\n\n    logfile    = \"dealership_logfile.txt\"            # all event logs will be stored\n    targetfile = \"dealership_transformed_data.csv\"   # transformed data is stored\n\n    log(logfile, \"Download Used Car Data\")\n    get_data()\n    log(logfile, \"ETL Job Started\")\n    log(logfile, \"Extract phase Started\")\n    extracted_data = extract() \n    print(extracted_data)\n    #extracted_data.to_csv (r'C:\\Users\\USUARIO\\OneDrive\\Escritorio\\U\\6to\\Base de Datos\\Parcial 2\\ETL\\export_dataframe.csv', index = False, header=True)\n    log(logfile, \"Extract phase Ended\")\n    log(logfile, \"Transform phase Started\")\n    transformed_data = transform(extracted_data)\n    print(transformed_data)\n    log(logfile, \"Transform phase Ended\")\n    log(logfile, \"Load phase Started\")\n    load(targetfile, transformed_data)\n    log(logfile, \"Load phase Ended\")\n    log(logfile, \"ETL Job Started\")\n\n","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Download Used Car Data\nIniciar descarga de archivos\nETL Job Started\nExtract phase Started\n        car_model year_of_manufacture         price    fuel\n0        alto 800                2017   4253.731343  Petrol\n1            ciaz                2015  10223.880597  Diesel\n2            ciaz                2015  11194.029851  Petrol\n3          ertiga                2015   9104.477612  Petrol\n4           dzire                2009   3358.208955  Petrol\n..            ...                 ...           ...     ...\n85     etios liva                2014   7089.552239  Diesel\n86         innova                2017  29477.611940  Petrol\n87       fortuner                2010  13805.970149  Diesel\n88  corolla altis                2011   6492.537313  Petrol\n89  corolla altis                2016  21268.656716  Petrol\n\n[90 rows x 4 columns]\nExtract phase Ended\nTransform phase Started\n        car_model year_of_manufacture     price    fuel\n0        alto 800                2017   4253.73  Petrol\n1            ciaz                2015  10223.88  Diesel\n2            ciaz                2015  11194.03  Petrol\n3          ertiga                2015   9104.48  Petrol\n4           dzire                2009   3358.21  Petrol\n..            ...                 ...       ...     ...\n85     etios liva                2014   7089.55  Diesel\n86         innova                2017  29477.61  Petrol\n87       fortuner                2010  13805.97  Diesel\n88  corolla altis                2011   6492.54  Petrol\n89  corolla altis                2016  21268.66  Petrol\n\n[90 rows x 4 columns]\nTransform phase Ended\nLoad phase Started\nLoad phase Ended\nETL Job Started\n","output_type":"stream"}],"id":"0d880f2e-0e41-4741-8c33-875f9cf8ddaa"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"1f0acfcf-3767-4b70-ac22-daeb28cc52c4"}]}